{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `Conv2D` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Conv2D` performs a 2 dimensional convolution. Here we will look into this layer, by going over its four main arguments ([docs](https://keras.io/api/layers/convolution_layers/convolution2d/)):\n",
    "* `filters`\n",
    "* `kernel_size`\n",
    "* `padding`\n",
    "* `stride`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual representation of `Conv2D` can be found on Keras' [references for `Conv2DTranspose` operation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose#references_1):\n",
    "\n",
    "* [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285v1). Its [Github repository](https://github.com/vdumoulin/conv_arithmetic) includes animated demonstrations\n",
    "* [Deconvolutional Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The animations below are taken from [conv_arithmetic](https://github.com/vdumoulin/conv_arithmetic/tree/master), in accordance with the MIT license."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No Padding, Strides=1**\n",
    "\n",
    "![no padding and no stride](../images/conv2d/no_padding_no_strides.gif)\n",
    "\n",
    "**Padding and Strides=1**\n",
    "\n",
    "![padding and no strides](../images/conv2d/full_padding_no_strides.gif)\n",
    "\n",
    "**No Padding and Strides=2**\n",
    "\n",
    "![no padding and strides](../images/conv2d/no_padding_strides.gif)\n",
    "\n",
    "**Padding and Strides=2**\n",
    "\n",
    "![padding and strides](../images/conv2d/padding_strides.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A single `Conv2D` layer\n",
    "Defining a model with a single `Conv2D` layer:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: `keras.Input` is a class in the Keras API that is used to instantiate a Keras tensor ([docs](https://keras.io/api/layers/core_layers/input/)). It is used to define the shape of the input data for a Keras model. In the given code excerpt, `keras.Input(shape=(8, 8, 1))` creates an input layer that takes in a 4D tensor with shape `(batch_size, 8, 8, 1)`. The `shape` parameter specifies the shape of the input tensor, where `8` is the height and width of the input image, and `1` is the number of channels (grayscale). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(8, 8, 1))\n",
    "x = layers.Conv2D(filters=3, kernel_size=2, activation=\"relu\", padding='VALID')(inputs)\n",
    "model = keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 8, 8, 1)]         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 3)           15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look into the model summary:\n",
    "* The `None` in a dimension stands for an arbitrary size - that means that it can change between training and inference (common), or during training (much less common). \n",
    "* The 15 parameters are nine weights and one bias term per kernel, for two kernels.\n",
    "* The spatial map is reduced from an 8 by 8 matrix to a 6 by 6. This is given the padding set to 'valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A `Conv2D` on an input with more than a single channel (size of depth axis > 1)\n",
    "\n",
    "Below we demonstrate a dimensional analysis for a case where the input layer is larger than one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(8, 8, 3))\n",
    "x = layers.Conv2D(filters=2, kernel_size=3, activation=\"relu\", padding='VALID')(inputs)\n",
    "model = keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 8, 8, 3)]         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 6, 6, 2)           56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The number of parameters increased from 20 to 56. The calculation is as follows:\n",
    "  * For each of the two kernels there are:\n",
    "    * 9 weights for each of the 3 depth levels (RGB) of the input, which results 27 weights.\n",
    "    * 1 bias\n",
    "  * 28 parameters per kernel, resulting in 56 parameters for two kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For each single value provided by a kernel, it performs a convolution across _all_ depth 'layers' of its input layer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is true regardless of where the input is. Look at the second layer of the network here, and validate that the number of its paramters is in according with the suggestion above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(8, 8, 3))\n",
    "x = layers.Conv2D(filters=2, kernel_size=3, activation=\"relu\", padding='VALID')(inputs)\n",
    "x = layers.Conv2D(filters=4, kernel_size=3, activation=\"relu\", padding='VALID')(x)\n",
    "model = keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 8, 8, 3)]         0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 6, 6, 2)           56        \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 4, 4, 4)           76        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132\n",
      "Trainable params: 132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To the student**: Why does the second layer has 38 parameters? Can you derive this number? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding\n",
    "\n",
    "Here we are changing the `padding` argument from `VALID` to `SAME`. Compare the model summary of the two cases.  What is different? Can you say why? Hint: looking at the [docs]([Title](https://keras.io/api/layers/convolution_layers/convolution2d/)) for the `Conv2D` class can provide some insight about the purpose of the `padding` argument. \n",
    "\n",
    "Advanced: the [Tensorflow notes](https://www.tensorflow.org/api_docs/python/tf/nn#notes_on_padding_2) on padding describe specific calculation, including edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(8, 8, 1))\n",
    "x = layers.Conv2D(filters=2, kernel_size=3, activation=\"relu\", padding='SAME')(inputs)\n",
    "model = keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 8, 8, 1)]         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 2)           20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stride\n",
    "\n",
    "The default stride is 1 of `Conv2D`.\n",
    "Let's compare it to a stride of 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = keras.Input(shape=(8, 8, 1))\n",
    "x = layers.Conv2D(filters=2, kernel_size=3, strides=2, activation=\"relu\", padding='SAME')(inputs)\n",
    "model = keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 8, 8, 1)]         0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 4, 4, 2)           20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To the student**: What is the difference between the model summary of this network to the one with the default `strides=1`? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `kernel_size` and the 1D Convolutional Layer (1x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(8, 8, 1))\n",
    "x = layers.Conv2D(filters=2, kernel_size=1, activation=\"relu\", padding='SAME')(inputs)\n",
    "model = keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 8, 8, 1)]         0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 8, 8, 2)           4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(8, 8, 3))\n",
    "x = layers.Conv2D(filters=2, kernel_size=1, activation=\"relu\", padding='SAME')(inputs)\n",
    "model = keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each kernel has 1 weight and 1 bias, totalling in 4 parameters for both kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 8, 8, 3)]         0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 2)           8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8\n",
      "Trainable params: 8\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To the student**: With three input channels, how are the number of parameters calculated for a 1D convolution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit Definition of a `Conv2D` filter\n",
    "\n",
    "The `conv2d` filter can be defined explicitly and directly by the user. This might be useful for learning purposes.\n",
    "\n",
    "`Keras'` `conv2d` layer is an abstraction of `tf.nn.conv2d`. Using `tf.nn.conv2d` directly allows us to define the filters directly, and observe the result of the computation ([docs](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input shape (`x_in`): `batch_shape + [in_height, in_width, in_channels]`\n",
    "\n",
    "Filter shape (`kernel_in`): `[filter_height, filter_width, in_channels, out_channels]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 5, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_in = np.array([[\n",
    "  [[2], [1], [2], [0], [1]],\n",
    "  [[1], [3], [2], [2], [3]],\n",
    "  [[1], [1], [3], [3], [0]],\n",
    "  [[2], [2], [0], [1], [1]],\n",
    "  [[0], [0], [3], [1], [2]], ]])\n",
    "\n",
    "x_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 1, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_in = np.array([\n",
    " [ [[2, 0.1]], [[3, 0.2]] ],\n",
    " [ [[0, 0.3]], [[1, 0.4]] ], ])\n",
    "\n",
    "kernel_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(x_in, dtype=tf.float32)\n",
    "kernel = tf.constant(kernel_in, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 4, 2), dtype=float32, numpy=\n",
       "array([[[[10.       ,  1.9000001],\n",
       "         [10.       ,  2.2      ],\n",
       "         [ 6.       ,  1.6      ],\n",
       "         [ 6.       ,  2.       ]],\n",
       "\n",
       "        [[12.       ,  1.4      ],\n",
       "         [15.       ,  2.2      ],\n",
       "         [13.       ,  2.7      ],\n",
       "         [13.       ,  1.7      ]],\n",
       "\n",
       "        [[ 7.       ,  1.7      ],\n",
       "         [11.       ,  1.3      ],\n",
       "         [16.       ,  1.3000001],\n",
       "         [ 7.       ,  1.       ]],\n",
       "\n",
       "        [[10.       ,  0.6      ],\n",
       "         [ 7.       ,  1.4      ],\n",
       "         [ 4.       ,  1.5      ],\n",
       "         [ 7.       ,  1.4000001]]]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.conv2d(x, kernel, strides=[1, 1, 1, 1], padding='VALID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
